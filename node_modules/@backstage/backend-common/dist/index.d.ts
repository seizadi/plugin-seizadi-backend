/// <reference types="node" />
/// <reference types="webpack-env" />
import { JsonValue, Config, ConfigReader } from '@backstage/config';
import * as winston from 'winston';
import { Logger } from 'winston';
import { Knex } from 'knex';
import express, { ErrorRequestHandler, RequestHandler, Router } from 'express';
import { AzureIntegration, BitbucketIntegration, GitHubIntegration, GithubCredentialsProvider, GitLabIntegration } from '@backstage/integration';
import { Readable, Writable } from 'stream';
import * as isomorphic_git from 'isomorphic-git';
import { MergeResult, ReadCommitResult } from 'isomorphic-git';
import cors from 'cors';
import * as http from 'http';
import { Server } from 'http';
import Docker from 'dockerode';
export { isChildPath } from '@backstage/cli-common';

declare type CacheSetOptions = {
    /**
     * Optional TTL in milliseconds. Defaults to the TTL provided when the client
     * was set up (or no TTL if none are provided).
     */
    ttl?: number;
};
/**
 * A pre-configured, storage agnostic cache client suitable for use by
 * Backstage plugins.
 */
interface CacheClient {
    /**
     * Reads data from a cache store for the given key. If no data was found,
     * returns undefined.
     */
    get(key: string): Promise<JsonValue | undefined>;
    /**
     * Writes the given data to a cache store, associated with the given key. An
     * optional TTL may also be provided, otherwise it defaults to the TTL that
     * was provided when the client was instantiated.
     */
    set(key: string, value: JsonValue, options?: CacheSetOptions): Promise<void>;
    /**
     * Removes the given key from the cache store.
     */
    delete(key: string): Promise<void>;
}

declare type ClientOptions = {
    /**
     * An optional default TTL (in milliseconds) to be set when getting a client
     * instance. If not provided, data will persist indefinitely by default (or
     * can be configured per entry at set-time).
     */
    defaultTtl?: number;
};
declare type OptionalOnError = ((err: Error) => void) | undefined;
declare type CacheManagerOptions = {
    /**
     * An optional logger for use by the PluginCacheManager.
     */
    logger?: Logger;
    /**
     * An optional handler for connection errors emitted from the underlying data
     * store.
     */
    onError?: OptionalOnError;
};
/**
 * The PluginCacheManager manages access to cache stores that Plugins get.
 */
declare type PluginCacheManager = {
    /**
     * getClient provides backend plugins cache connections for itself.
     *
     * The purpose of this method is to allow plugins to get isolated data
     * stores so that plugins are discouraged from cache-level integration
     * and/or cache key collisions.
     */
    getClient: (options?: ClientOptions) => CacheClient;
};

/**
 * Implements a Cache Manager which will automatically create new cache clients
 * for plugins when requested. All requested cache clients are created with the
 * connection details provided.
 */
declare class CacheManager {
    /**
     * Keys represent supported `backend.cache.store` values, mapped to factories
     * that return Keyv instances appropriate to the store.
     */
    private readonly storeFactories;
    private readonly logger;
    private readonly store;
    private readonly connection;
    private readonly errorHandler;
    /**
     * Creates a new CacheManager instance by reading from the `backend` config
     * section, specifically the `.cache` key.
     *
     * @param config The loaded application configuration.
     */
    static fromConfig(config: Config, options?: CacheManagerOptions): CacheManager;
    private constructor();
    /**
     * Generates a PluginCacheManager for consumption by plugins.
     *
     * @param pluginId The plugin that the cache manager should be created for. Plugin names should be unique.
     */
    forPlugin(pluginId: string): PluginCacheManager;
    private getClientWithTtl;
    private getMemcacheClient;
    private getMemoryClient;
    private getNoneClient;
}

declare type Options = {
    logger: Logger;
    argv: string[];
};
/**
 * Load configuration for a Backend.
 *
 * This function should only be called once, during the initialization of the backend.
 */
declare function loadBackendConfig(options: Options): Promise<Config>;

/**
 * The PluginDatabaseManager manages access to databases that Plugins get.
 */
interface PluginDatabaseManager {
    /**
     * getClient provides backend plugins database connections for itself.
     *
     * The purpose of this method is to allow plugins to get isolated data
     * stores so that plugins are discouraged from database integration.
     */
    getClient(): Promise<Knex>;
}

declare class DatabaseManager {
    private readonly config;
    private readonly prefix;
    /**
     * Creates a DatabaseManager from `backend.database` config.
     *
     * The database manager allows the user to set connection and client settings on a per pluginId
     * basis by defining a database config block under `plugin.<pluginId>` in addition to top level
     * defaults. Optionally, a user may set `prefix` which is used to prefix generated database
     * names if config is not provided.
     *
     * @param config The loaded application configuration.
     */
    static fromConfig(config: Config): DatabaseManager;
    private constructor();
    /**
     * Generates a PluginDatabaseManager for consumption by plugins.
     *
     * @param pluginId The plugin that the database manager should be created for. Plugin names
     * should be unique as they are used to look up database config overrides under
     * `backend.database.plugin`.
     */
    forPlugin(pluginId: string): PluginDatabaseManager;
    /**
     * Provides the canonical database name for a given plugin.
     *
     * This method provides the effective database name which is determined using global
     * and plugin specific database config. If no explicit database name is configured,
     * this method will provide a generated name which is the pluginId prefixed with
     * 'backstage_plugin_'.
     *
     * @param pluginId Lookup the database name for given plugin
     * @returns String representing the plugin's database name
     */
    private getDatabaseName;
    /**
     * Provides the client type which should be used for a given plugin.
     *
     * The client type is determined by plugin specific config if present. Otherwise the base
     * client is used as the fallback.
     *
     * @param pluginId Plugin to get the client type for
     * @returns Object with client type returned as `client` and boolean representing whether
     * or not the client was overridden as `overridden`
     */
    private getClientType;
    private getEnsureExistsConfig;
    /**
     * Provides a Knex connection plugin config by combining base and plugin config.
     *
     * This method provides a baseConfig for a plugin database connector. If the client type
     * has not been overridden, the global connection config will be included with plugin
     * specific config as the base. Values from the plugin connection take precedence over the
     * base. Base database name is omitted for all supported databases excluding SQLite.
     */
    private getConnectionConfig;
    /**
     * Provides a Knex database config for a given plugin.
     *
     * This method provides a Knex configuration object along with the plugin's client type.
     *
     * @param pluginId The plugin that the database config should correspond with
     */
    private getConfigForPlugin;
    /**
     * Provides a partial Knex.Config database name override for a given plugin.
     *
     * @param pluginId Target plugin to get database name override
     * @returns Partial Knex.Config with database name override
     */
    private getDatabaseOverrides;
    /**
     * Provides a scoped Knex client for a plugin as per application config.
     *
     *  @param pluginId Plugin to get a Knex client for
     *  @returns Promise which resolves to a scoped Knex database client for a plugin
     */
    private getDatabase;
}

/**
 * Implements a Database Manager which will automatically create new databases
 * for plugins when requested. All requested databases are created with the
 * credentials provided; if the database already exists no attempt to create
 * the database will be made.
 *
 * @deprecated Use `DatabaseManager` from `@backend-common` instead.
 */
declare const SingleConnectionDatabaseManager: typeof DatabaseManager;

/**
 * Creates a knex database connection
 *
 * @param dbConfig The database config
 * @param overrides Additional options to merge with the config
 */
declare function createDatabaseClient(dbConfig: Config, overrides?: Partial<Knex.Config>): Knex<any, unknown[]>;
/**
 * Alias for createDatabaseClient
 * @deprecated Use createDatabaseClient instead
 */
declare const createDatabase: typeof createDatabaseClient;
/**
 * Ensures that the given databases all exist, creating them if they do not.
 */
declare function ensureDatabaseExists(dbConfig: Config, ...databases: Array<string>): Promise<void>;

/**
 * The PluginEndpointDiscovery is used to provide a mechanism for backend
 * plugins to discover the endpoints for itself or other backend plugins.
 *
 * The purpose of the discovery API is to allow for many different deployment
 * setups and routing methods through a central configuration, instead
 * of letting each individual plugin manage that configuration.
 *
 * Implementations of the discovery API can be as simple as a URL pattern
 * using the pluginId, but could also have overrides for individual plugins,
 * or query a separate discovery service.
 */
declare type PluginEndpointDiscovery = {
    /**
     * Returns the internal HTTP base URL for a given plugin, without a trailing slash.
     *
     * The returned URL should point to an internal endpoint for the plugin, with
     * the shortest route possible. The URL should be used for service-to-service
     * communication within a Backstage backend deployment.
     *
     * This method must always be called just before making a request, as opposed to
     * fetching the URL when constructing an API client. That is to ensure that more
     * flexible routing patterns can be supported.
     *
     * For example, asking for the URL for `catalog` may return something
     * like `http://10.1.2.3/api/catalog`
     */
    getBaseUrl(pluginId: string): Promise<string>;
    /**
     * Returns the external HTTP base backend URL for a given plugin, without a trailing slash.
     *
     * The returned URL should point to an external endpoint for the plugin, such that
     * it is reachable from the Backstage frontend and other external services. The returned
     * URL should be usable for example as a callback / webhook URL.
     *
     * The returned URL should be stable and in general not change unless other static
     * or external configuration is changed. Changes should not come as a surprise
     * to an operator of the Backstage backend.
     *
     * For example, asking for the URL for `catalog` may return something
     * like `https://backstage.example.com/api/catalog`
     */
    getExternalBaseUrl(pluginId: string): Promise<string>;
};

/**
 * SingleHostDiscovery is a basic PluginEndpointDiscovery implementation
 * that assumes that all plugins are hosted in a single deployment.
 *
 * The deployment may be scaled horizontally, as long as the external URL
 * is the same for all instances. However, internal URLs will always be
 * resolved to the same host, so there won't be any balancing of internal traffic.
 */
declare class SingleHostDiscovery implements PluginEndpointDiscovery {
    private readonly internalBaseUrl;
    private readonly externalBaseUrl;
    /**
     * Creates a new SingleHostDiscovery discovery instance by reading
     * from the `backend` config section, specifically the `.baseUrl` for
     * discovering the external URL, and the `.listen` and `.https` config
     * for the internal one.
     *
     * The basePath defaults to `/api`, meaning the default full internal
     * path for the `catalog` plugin will be `http://localhost:7000/api/catalog`.
     */
    static fromConfig(config: Config, options?: {
        basePath?: string;
    }): SingleHostDiscovery;
    private constructor();
    getBaseUrl(pluginId: string): Promise<string>;
    getExternalBaseUrl(pluginId: string): Promise<string>;
}

/**
 * useHotCleanup allows cleanup of ongoing effects when a module is
 * hot-reloaded during development. The cleanup function will be called
 * whenever the module itself or any of its parent modules is hot-reloaded.
 *
 * Useful for cleaning intervals, timers, requests etc
 *
 * @example
 * ```ts
 * const intervalId = setInterval(doStuff, 1000);
 * useHotCleanup(module, () => clearInterval(intervalId));
 * ```
 * @param _module Reference to the current module where you invoke the fn
 * @param cancelEffect Fn that cleans up the ongoing effects
 */
declare function useHotCleanup(_module: NodeModule, cancelEffect: () => void): void;
/**
 * Memoizes a generated value across hot-module reloads. This is useful for
 * stateful parts of the backend, e.g. to retain a database.
 *
 * @example
 * ```ts
 * const db = useHotMemoize(module, () => createDB(dbParams));
 * ```
 *
 * @warning Don't use inside conditionals or loops,
 * same rules as for hooks apply (https://reactjs.org/docs/hooks-rules.html)
 *
 * @param _module Reference to the current module where you invoke the fn
 * @param valueFactory Fn that returns the value you want to memoize
 */
declare function useHotMemoize<T>(_module: NodeModule, valueFactory: () => T): T;

declare const coloredFormat: winston.Logform.Format;

declare function getRootLogger(): winston.Logger;
declare function setRootLogger(newLogger: winston.Logger): void;
declare function createRootLogger(options?: winston.LoggerOptions, env?: NodeJS.ProcessEnv): winston.Logger;

/**
 * A logger that just throws away all messages.
 */
declare function getVoidLogger(): winston.Logger;

declare type ErrorHandlerOptions = {
    /**
     * Whether error response bodies should show error stack traces or not.
     *
     * If not specified, by default shows stack traces only in development mode.
     */
    showStackTraces?: boolean;
    /**
     * Logger instance to log errors.
     *
     * If not specified, the root logger will be used.
     */
    logger?: Logger;
    /**
     * Whether any error < 4XX should be logged or not.
     *
     * If not specified, by default log any 5xx errors.
     */
    logClientErrors?: boolean;
};
/**
 * Express middleware to handle errors during request processing.
 *
 * This is commonly the very last middleware in the chain.
 *
 * Its primary purpose is not to do translation of business logic exceptions,
 * but rather to be a global catch-all for uncaught "fatal" errors that are
 * expected to result in a 500 error. However, it also does handle some common
 * error types (such as http-error exceptions) and returns the enclosed status
 * code accordingly.
 *
 * @returns An Express error request handler
 */
declare function errorHandler(options?: ErrorHandlerOptions): ErrorRequestHandler;

/**
 * Express middleware to handle requests for missing routes.
 *
 * Should be used as the very last handler in the chain, as it unconditionally
 * returns a 404 status.
 *
 * @returns An Express request handler
 */
declare function notFoundHandler(): RequestHandler;

/**
 * Logs incoming requests.
 *
 * @param logger An optional logger to use. If not specified, the root logger will be used.
 * @returns An Express request handler
 */
declare function requestLoggingHandler(logger?: Logger): RequestHandler;

declare type StatusCheck = () => Promise<any>;
interface StatusCheckHandlerOptions {
    /**
     * Optional status function which returns a message.
     */
    statusCheck?: StatusCheck;
}
/**
 * Express middleware for status checks.
 *
 * This is commonly used to implement healthcheck and readiness routes.
 *
 * @param options An optional configuration object.
 * @returns An Express error request handler
 */
declare function statusCheckHandler(options?: StatusCheckHandlerOptions): Promise<RequestHandler>;

/**
 * Resolve a path relative to the root of a package directory.
 * Additional path arguments are resolved relative to the package dir.
 *
 * This is particularly useful when you want to access assets shipped with
 * your backend plugin package. When doing so, do not forget to include the assets
 * in your published package by adding them to `files` in your `package.json`.
 */
declare function resolvePackagePath(name: string, ...paths: string[]): string;
/**
 * Resolves a target path from a base path while guaranteeing that the result is
 * a path that point to or within the base path. This is useful for resolving
 * paths from user input, as it otherwise opens up for vulnerabilities.
 *
 * @param base The base directory to resolve the path from.
 * @param path The target path, relative or absolute
 * @returns A path that is guaranteed to point to or within the base path.
 */
declare function resolveSafeChildPath(base: string, path: string): string;

/**
 * A generic interface for fetching plain data from URLs.
 */
declare type UrlReader = {
    read(url: string): Promise<Buffer>;
    /**
     * A replacement for the read method that supports options and complex responses.
     *
     * Use this whenever it is available, as the read method will be deprecated and
     * eventually removed in the future.
     */
    readUrl?(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
};
declare type UrlReaderPredicateTuple = {
    predicate: (url: URL) => boolean;
    reader: UrlReader;
};
/**
 * A factory function that can read config to construct zero or more
 * UrlReaders along with a predicate for when it should be used.
 */
declare type ReaderFactory = (options: {
    config: Config;
    logger: Logger;
    treeResponseFactory: ReadTreeResponseFactory;
}) => UrlReaderPredicateTuple[];
/**
 * An options object for readUrl operations.
 */
declare type ReadUrlOptions = {
    /**
     * An etag can be provided to check whether readUrl's response has changed from a previous execution.
     *
     * In the readUrl() response, an etag is returned along with the data. The etag is a unique identifer
     * of the data, usually the commit SHA or etag from the target.
     *
     * When an etag is given in ReadUrlOptions, readUrl will first compare the etag against the etag
     * on the target. If they match, readUrl will throw a NotModifiedError indicating that the readUrl
     * response will not differ from the previous response which included this particular etag. If they
     * do not match, readUrl will return the rest of ReadUrlResponse along with a new etag.
     */
    etag?: string;
};
/**
 * A response object for readUrl operations.
 */
declare type ReadUrlResponse = {
    /**
     * Returns the data that was read from the remote URL.
     */
    buffer(): Promise<Buffer>;
    /**
     * Etag returned by content provider.
     * Can be used to compare and cache responses when doing subsequent calls.
     */
    etag?: string;
};
/**
 * An options object for readTree operations.
 */
declare type ReadTreeOptions = {
    /**
     * A filter that can be used to select which files should be included.
     *
     * The path passed to the filter function is the relative path from the URL
     * that the file tree is fetched from, without any leading '/'.
     *
     * For example, given the URL https://github.com/my/repo/tree/master/my-dir, a file
     * at https://github.com/my/repo/blob/master/my-dir/my-subdir/my-file.txt will
     * be represented as my-subdir/my-file.txt
     *
     * If no filter is provided all files are extracted.
     */
    filter?(path: string, info?: {
        size: number;
    }): boolean;
    /**
     * An etag can be provided to check whether readTree's response has changed from a previous execution.
     *
     * In the readTree() response, an etag is returned along with the tree blob. The etag is a unique identifer
     * of the tree blob, usually the commit SHA or etag from the target.
     *
     * When an etag is given in ReadTreeOptions, readTree will first compare the etag against the etag
     * on the target branch. If they match, readTree will throw a NotModifiedError indicating that the readTree
     * response will not differ from the previous response which included this particular etag. If they
     * do not match, readTree will return the rest of ReadTreeResponse along with a new etag.
     */
    etag?: string;
};
/**
 * A response object for readTree operations.
 */
declare type ReadTreeResponse = {
    /**
     * files() returns an array of all the files inside the tree and corresponding functions to read their content.
     */
    files(): Promise<ReadTreeResponseFile[]>;
    archive(): Promise<NodeJS.ReadableStream>;
    /**
     * dir() extracts the tree response into a directory and returns the path of the directory.
     */
    dir(options?: ReadTreeResponseDirOptions): Promise<string>;
    /**
     * Etag returned by content provider.
     * Can be used to compare and cache responses when doing subsequent calls.
     */
    etag: string;
};
declare type ReadTreeResponseDirOptions = {
    /** The directory to write files to. Defaults to the OS tmpdir or `backend.workingDirectory` if set in config */
    targetDir?: string;
};
/**
 * Represents a single file in a readTree response.
 */
declare type ReadTreeResponseFile = {
    path: string;
    content(): Promise<Buffer>;
};
declare type FromArchiveOptions = {
    stream: Readable;
    subpath?: string;
    etag: string;
    filter?: (path: string, info?: {
        size: number;
    }) => boolean;
};
interface ReadTreeResponseFactory {
    fromTarArchive(options: FromArchiveOptions): Promise<ReadTreeResponse>;
    fromZipArchive(options: FromArchiveOptions): Promise<ReadTreeResponse>;
}
/**
 * An options object for search operations.
 */
declare type SearchOptions = {
    /**
     * An etag can be provided to check whether the search response has changed from a previous execution.
     *
     * In the search() response, an etag is returned along with the files. The etag is a unique identifer
     * of the current tree, usually the commit SHA or etag from the target.
     *
     * When an etag is given in SearchOptions, search will first compare the etag against the etag
     * on the target branch. If they match, search will throw a NotModifiedError indicating that the search
     * response will not differ from the previous response which included this particular etag. If they mismatch,
     * search will return the rest of SearchResponse along with a new etag.
     */
    etag?: string;
};
/**
 * The output of a search operation.
 */
declare type SearchResponse = {
    /**
     * The files that matched the search query.
     */
    files: SearchResponseFile[];
    /**
     * A unique identifer of the current remote tree, usually the commit SHA or etag from the target.
     */
    etag: string;
};
/**
 * Represents a single file in a search response.
 */
declare type SearchResponseFile = {
    /**
     * The full URL to the file.
     */
    url: string;
    /**
     * The binary contents of the file.
     */
    content(): Promise<Buffer>;
};

declare class AzureUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: AzureIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, _options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
}

/**
 * A processor that adds the ability to read files from Bitbucket v1 and v2 APIs, such as
 * the one exposed by Bitbucket Cloud itself.
 */
declare class BitbucketUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: BitbucketIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, _options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
    private getLastCommitShortHash;
}

/**
 * A processor that adds the ability to read files from GitHub v3 APIs, such as
 * the one exposed by GitHub itself.
 */
declare class GithubUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: GitHubIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
        credentialsProvider: GithubCredentialsProvider;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
    private doReadTree;
    private doSearch;
    private getRepoDetails;
    private fetchResponse;
    private fetchJson;
}

declare class GitlabUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: GitLabIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
}

declare type CreateOptions = {
    /** Root config object */
    config: Config;
    /** Logger used by all the readers */
    logger: Logger;
    /** A list of factories used to construct individual readers that match on URLs */
    factories?: ReaderFactory[];
};
/**
 * UrlReaders provide various utilities related to the UrlReader interface.
 */
declare class UrlReaders {
    /**
     * Creates a UrlReader without any known types.
     */
    static create({ logger, config, factories }: CreateOptions): UrlReader;
    /**
     * Creates a UrlReader that includes all the default factories from this package.
     *
     * Any additional factories passed will be loaded before the default ones.
     */
    static default({ logger, config, factories }: CreateOptions): UrlReader;
}

declare class Git {
    private readonly config;
    private constructor();
    add({ dir, filepath, }: {
        dir: string;
        filepath: string;
    }): Promise<void>;
    addRemote({ dir, url, remote, }: {
        dir: string;
        remote: string;
        url: string;
    }): Promise<void>;
    commit({ dir, message, author, committer, }: {
        dir: string;
        message: string;
        author: {
            name: string;
            email: string;
        };
        committer: {
            name: string;
            email: string;
        };
    }): Promise<string>;
    clone({ url, dir, ref, }: {
        url: string;
        dir: string;
        ref?: string;
    }): Promise<void>;
    currentBranch({ dir, fullName, }: {
        dir: string;
        fullName?: boolean;
    }): Promise<string | undefined>;
    fetch({ dir, remote, }: {
        dir: string;
        remote?: string;
    }): Promise<void>;
    init({ dir, defaultBranch, }: {
        dir: string;
        defaultBranch?: string;
    }): Promise<void>;
    merge({ dir, theirs, ours, author, committer, }: {
        dir: string;
        theirs: string;
        ours?: string;
        author: {
            name: string;
            email: string;
        };
        committer: {
            name: string;
            email: string;
        };
    }): Promise<MergeResult>;
    push({ dir, remote }: {
        dir: string;
        remote: string;
    }): Promise<isomorphic_git.PushResult>;
    readCommit({ dir, sha, }: {
        dir: string;
        sha: string;
    }): Promise<ReadCommitResult>;
    resolveRef({ dir, ref, }: {
        dir: string;
        ref: string;
    }): Promise<string>;
    private onAuth;
    private onProgressHandler;
    static fromAuth: ({ username, password, logger, }: {
        username?: string | undefined;
        password?: string | undefined;
        logger?: Logger | undefined;
    }) => Git;
}

declare type HttpsSettings = {
    certificate: CertificateGenerationOptions | CertificateReferenceOptions;
};
declare type CertificateReferenceOptions = {
    key: string;
    cert: string;
};
declare type CertificateGenerationOptions = {
    hostname: string;
};
/**
 * A map from CSP directive names to their values.
 *
 * Added here since helmet doesn't export this type publicly.
 */
declare type CspOptions = Record<string, string[]>;

declare type ServiceBuilder = {
    /**
     * Sets the service parameters based on configuration.
     *
     * @param config The configuration to read
     */
    loadConfig(config: ConfigReader): ServiceBuilder;
    /**
     * Sets the port to listen on.
     *
     * If no port is specified, the service will first look for an environment
     * variable named PORT and use that if present, otherwise it picks a default
     * port (7000).
     *
     * @param port The port to listen on
     */
    setPort(port: number): ServiceBuilder;
    /**
     * Sets the host to listen on.
     *
     * '' is express default, which listens to all interfaces.
     *
     * @param host The host to listen on
     */
    setHost(host: string): ServiceBuilder;
    /**
     * Sets the logger to use for service-specific logging.
     *
     * If no logger is given, the default root logger is used.
     *
     * @param logger A winston logger
     */
    setLogger(logger: Logger): ServiceBuilder;
    /**
     * Enables CORS handling using the given settings.
     *
     * If this method is not called, the resulting service will not have any
     * built in CORS handling.
     *
     * @param options Standard CORS options
     */
    enableCors(options: cors.CorsOptions): ServiceBuilder;
    /**
     * Configure self-signed certificate generation options.
     *
     * If this method is not called, the resulting service will use sensible defaults
     *
     * @param options Standard certificate options
     */
    setHttpsSettings(settings: HttpsSettings): ServiceBuilder;
    /**
     * Adds a router (similar to the express .use call) to the service.
     *
     * @param root The root URL to bind to (e.g. "/api/function1")
     * @param router An express router
     */
    addRouter(root: string, router: Router | RequestHandler): ServiceBuilder;
    /**
     * Set the request logging handler
     *
     * If no handler is given the default one is used
     *
     * @param requestLoggingHandler a factory function that given a logger returns an handler
     */
    setRequestLoggingHandler(requestLoggingHandler: RequestLoggingHandlerFactory): ServiceBuilder;
    /**
     * Starts the server using the given settings.
     */
    start(): Promise<Server>;
};
declare type RequestLoggingHandlerFactory = (logger?: Logger) => RequestHandler;

declare class ServiceBuilderImpl implements ServiceBuilder {
    private port;
    private host;
    private logger;
    private corsOptions;
    private cspOptions;
    private httpsSettings;
    private routers;
    private requestLoggingHandler;
    private module;
    constructor(moduleRef: NodeModule);
    loadConfig(config: Config): ServiceBuilder;
    setPort(port: number): ServiceBuilder;
    setHost(host: string): ServiceBuilder;
    setLogger(logger: Logger): ServiceBuilder;
    setHttpsSettings(settings: HttpsSettings): ServiceBuilder;
    enableCors(options: cors.CorsOptions): ServiceBuilder;
    setCsp(options: CspOptions): ServiceBuilder;
    addRouter(root: string, router: Router): ServiceBuilder;
    setRequestLoggingHandler(requestLoggingHandler: RequestLoggingHandlerFactory): this;
    start(): Promise<http.Server>;
    private getOptions;
}

/**
 * Creates a new service builder.
 */
declare function createServiceBuilder(_module: NodeModule): ServiceBuilderImpl;

interface StatusCheckRouterOptions {
    logger: Logger;
    path?: string;
    /**
     * If not implemented, the default express middleware always returns 200.
     * Override this to implement your own logic for a health check.
     */
    statusCheck?: StatusCheck;
}
declare function createStatusCheckRouter(options: StatusCheckRouterOptions): Promise<express.Router>;

declare type RunContainerOptions = {
    imageName: string;
    command?: string | string[];
    args: string[];
    logStream?: Writable;
    mountDirs?: Record<string, string>;
    workingDir?: string;
    envVars?: Record<string, string>;
    pullImage?: boolean;
};
interface ContainerRunner {
    runContainer(opts: RunContainerOptions): Promise<void>;
}

declare class DockerContainerRunner implements ContainerRunner {
    private readonly dockerClient;
    constructor({ dockerClient }: {
        dockerClient: Docker;
    });
    runContainer({ imageName, command, args, logStream, mountDirs, workingDir, envVars, pullImage, }: RunContainerOptions): Promise<void>;
}

export { AzureUrlReader, BitbucketUrlReader, CacheClient, CacheManager, ContainerRunner, DatabaseManager, DockerContainerRunner, ErrorHandlerOptions, Git, GithubUrlReader, GitlabUrlReader, PluginCacheManager, PluginDatabaseManager, PluginEndpointDiscovery, ReadTreeResponse, ReadTreeResponseFile, RequestLoggingHandlerFactory, RunContainerOptions, SearchResponse, SearchResponseFile, ServiceBuilder, SingleConnectionDatabaseManager, SingleHostDiscovery, StatusCheck, StatusCheckHandlerOptions, UrlReader, UrlReaders, coloredFormat, createDatabase, createDatabaseClient, createRootLogger, createServiceBuilder, createStatusCheckRouter, ensureDatabaseExists, errorHandler, getRootLogger, getVoidLogger, loadBackendConfig, notFoundHandler, requestLoggingHandler, resolvePackagePath, resolveSafeChildPath, setRootLogger, statusCheckHandler, useHotCleanup, useHotMemoize };
